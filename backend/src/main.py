from fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, StreamingResponse
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import uuid
import json
import asyncio
from datetime import datetime, timezone
import os
import logging
import sys
import httpx
import psutil
import redis



from dotenv import load_dotenv
from .gitlab_integration import init_gitlab, get_gitlab_repos, commit_tests_to_gitlab
from .testplan_generator import TestPlanGenerator
from .llm_client import LLMClient
from .openapi_parser import OpenAPIParser
from .testcase_generator import TestCaseGenerator
from .autotest_generator import AutotestGenerator
from .optimizer import TestOptimizer
from .standards_checker import StandardsChecker
from .storage import StorageManager
from .models import *

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –≤—ã–≤–æ–¥–æ–º –≤ stdout
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

file_handler = logging.FileHandler('app.log')
file_handler.setLevel(logging.DEBUG)
logging.getLogger().addHandler(file_handler)

logger = logging.getLogger(__name__)

# –£—Å—Ç–∞–Ω–æ–≤–∏–º —É—Ä–æ–≤–µ–Ω—å –¥–ª—è uvicorn –ª–æ–≥–æ–≤ —Ç–æ–∂–µ
logging.getLogger("uvicorn").setLevel(logging.INFO)
logging.getLogger("uvicorn.access").setLevel(logging.INFO)

app = FastAPI(
    title="TestOps Copilot API",
    description="AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã QA-–∏–Ω–∂–µ–Ω–µ—Ä–∞",
    version="1.0.0"
)

# allow_origins=["http://localhost:3000", "http://localhost:5173"],
# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
llm_client = LLMClient()
storage = StorageManager()
testcase_generator = TestCaseGenerator(llm_client)
autotest_generator = AutotestGenerator(llm_client)
optimizer = TestOptimizer(llm_client)
standards_checker = StandardsChecker()
testplan_generator = TestPlanGenerator(llm_client)

@app.get("/")
async def root():
    return {"message": "TestOps Copilot API", "version": "1.0.0"}

@app.get("/api/config/")
async def get_config():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã"""
    compute_status = False
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                "https://compute.api.cloud.ru/api/v1/flavors",
                timeout=5.0
            )
            
            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∞–µ–º 401 (Unauthorized) –∏–ª–∏ 403 (Forbidden) - API –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –Ω—É–∂–Ω–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
            # –ï—Å–ª–∏ 200 - –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç
            if response.status_code in [200, 401, 403]:
                compute_status = True
    except Exception as e:
        logger.error(f"Compute check failed: {e}")

    return {
        "llm_model": os.getenv("LLM_MODEL", "openai/gpt-oss-120b"),
        "llm_available": llm_client.check_availability(),
        "compute_endpoint": "https://compute.api.cloud.ru",
        "compute_available": compute_status,
        "gitlab_configured": bool(os.getenv("GITLAB_TOKEN")),
        "environment": os.getenv("ENVIRONMENT", "development")
    }

@app.post("/api/config/llm/validate")
async def validate_llm(
    api_key: str = Form(...),
    model: str = Form(...),
    base_url: str = Form(...)
):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM"""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        result = llm_client.test_connection(
            api_key=api_key,
            base_url=base_url,
            model=model
        )
        if result.get("success"):
            return {"valid": True, "model": model, "base_url": base_url}
        else:
            return {"valid": False, "error": result.get("error", "Unknown error")}
    except Exception as e:
        return {"valid": False, "error": str(e)}

@app.post("/api/config/compute/validate")
async def validate_compute(data: ComputeValidationRequest):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Compute API"""
    
    token = data.token or os.getenv("COMPUTE_TOKEN") or os.getenv("COMPUTE_API_KEY")
    
    if not token:
        return {
            "valid": False,
            "endpoint": "https://compute.api.cloud.ru",
            "error": "–¢–æ–∫–µ–Ω –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω. –£–∫–∞–∂–∏—Ç–µ token –≤ –∑–∞–ø—Ä–æ—Å–µ –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è COMPUTE_TOKEN"
        }
    
    try:
        async with httpx.AsyncClient() as client:
            headers = {"Authorization": f"Bearer {token}"}
            
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–ª–µ–π–≤–æ—Ä–æ–≤
            response = await client.get(
                "https://compute.api.cloud.ru/api/v1/flavors",
                headers=headers,
                timeout=10.0
            )
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
                    if "items" in data or isinstance(data, list):
                        available_resources = ["vms", "disks", "flavors"]  # –ë–∞–∑–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã
                        # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
                        if "items" in data and len(data["items"]) > 0:
                            item = data["items"][0]
                            if "type" in item:
                                resource_type = item["type"]
                                if resource_type == "vm":
                                    available_resources = ["vms", "disks"]
                                elif resource_type == "disk":
                                    available_resources = ["disks", "flavors"]
                        
                        return {
                            "valid": True,
                            "endpoint": "https://compute.api.cloud.ru",
                            "available_resources": available_resources,
                            "authenticated": True
                        }
                except:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –Ω–æ —Å—Ç–∞—Ç—É—Å 200
                    return {
                        "valid": True,
                        "endpoint": "https://compute.api.cloud.ru",
                        "available_resources": ["vms", "disks", "flavors"],
                        "authenticated": True
                    }
            elif response.status_code == 401:
                return {
                    "valid": False,
                    "endpoint": "https://compute.api.cloud.ru",
                    "error": "–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω"
                }
            elif response.status_code == 403:
                return {
                    "valid": False,
                    "endpoint": "https://compute.api.cloud.ru",
                    "error": "–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤"
                }
            else:
                return {
                    "valid": False,
                    "endpoint": "https://compute.api.cloud.ru",
                    "error": f"API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}: {response.text[:100]}"
                }
                
    except httpx.TimeoutException:
        return {
            "valid": False,
            "endpoint": "https://compute.api.cloud.ru",
            "error": "–¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Compute API"
        }
    except Exception as e:
        return {
            "valid": False,
            "endpoint": "https://compute.api.cloud.ru",
            "error": f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}"
        }


# ==================== GITLAB INTEGRATION ====================

@app.post("/api/integrations/gitlab/init")
async def init_gitlab_integration(data: GitLabInitRequest):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GitLab –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    result = await init_gitlab(data.token, data.gitlab_url)
    return result

@app.post("/api/integrations/gitlab/repos")
async def get_gitlab_repositories(data: GitLabReposRequest):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤"""
    try:
        repos = await get_gitlab_repos(data.token, data.search)
        return {"success": True, "repositories": repos}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/integrations/gitlab/commit-tests")
async def commit_testcases_to_gitlab(data: GitLabCommitRequest):
    """–ö–æ–º–º–∏—Ç —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤ –≤ GitLab —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π"""
    result = await commit_tests_to_gitlab(
        token=data.token,
        project_id=data.project_id,
        testcases=data.testcases,
        directory=data.directory,
        branch=data.branch,
        commit_message=data.commit_message
    )
    return result

@app.get("/api/config/health/detailed")
async def get_detailed_health():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ LLM
    llm_status = "healthy" if llm_client.check_availability() else "unhealthy"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis
    redis_status = "healthy"
    redis_connection = True
    try:
        # –ü—Ä–æ–±—É–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç—å ping –∫ Redis
        redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))
        redis_client.ping()
        redis_client.close()
    except Exception as e:
        logger.error(f"Redis health check failed: {e}")
        redis_status = "unhealthy"
        redis_connection = False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Storage
    storage_status = "healthy"
    available_space = "unknown"
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ storage
        storage_path = os.getenv("STORAGE_PATH", "./storage")
        os.makedirs(storage_path, exist_ok=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
        disk_usage = psutil.disk_usage(storage_path)
        available_gb = disk_usage.free // (1024**3)
        available_space = f"{available_gb}GB"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏
        test_file = os.path.join(storage_path, ".health_check")
        with open(test_file, "w") as f:
            f.write("test")
        os.remove(test_file)
        
    except Exception as e:
        logger.error(f"Storage health check failed: {e}")
        storage_status = "unhealthy"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Compute API
    compute_status = "unknown"
    compute_response_time = None
    
    try:
        async with httpx.AsyncClient() as client:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–ª–µ–π–≤–æ—Ä–æ–≤ –±–µ–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å 401/403)
            start_time = datetime.now()
            response = await client.get(
                "https://compute.api.cloud.ru/api/v1/flavors",
                timeout=5.0
            )
            response_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∞–µ–º 401 (Unauthorized) –∏–ª–∏ 403 (Forbidden) - API –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –Ω—É–∂–Ω–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
            # –ï—Å–ª–∏ 200 - –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç
            if response.status_code in [200, 401, 403]:
                compute_status = "healthy"
                compute_response_time = round(response_time, 2)
            else:
                compute_status = "unhealthy"
                
    except httpx.TimeoutException:
        compute_status = "timeout"
    except Exception as e:
        logger.error(f"Compute API health check failed: {e}")
        compute_status = "unhealthy"
    
    return {
        "llm": {
            "status": llm_status,
            "model": os.getenv("LLM_MODEL"),
            "response_time": 150  # ms
        },
        "redis": {
            "status": redis_status,
            "connection": redis_connection
        },
        "storage": {
            "status": storage_status,
            "available_space": available_space,
            "path": os.getenv("STORAGE_PATH", "./storage")
        },
        "compute": {
            "status": compute_status,
            "response_time_ms": compute_response_time,
            "endpoint": "https://compute.api.cloud.ru"
        }
    }

@app.post("/api/testcases/manual/ui")
async def generate_manual_ui_testcases(data: UIGenerationRequest, background_tasks: BackgroundTasks):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—É—á–Ω—ã—Ö UI —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤"""
    job_id = str(uuid.uuid4())
    
    async def generate_task():
        try:
            logger.info(f"–ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ UI —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤ –¥–ª—è job_id: {job_id}")
            logger.debug(f"–î–∞–Ω–Ω—ã–µ: {data.dict()}")
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            await storage.update_job_status(job_id, "processing", None, None, 25)
        
            testcases = await testcase_generator.generate_ui_testcases(
                requirements=data.requirements,
                test_blocks=data.test_blocks,
                target_count=data.target_count,
                priority=data.priority
            )
            
            logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(testcases) if testcases else 0} —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤")
            
            await storage.update_job_status(job_id, "processing", None, None, 75)

            await storage.save_testcases(job_id, testcases, "manual_ui")
            await storage.update_job_status(job_id, "completed", testcases, None, 100)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ UI —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤: {e}", exc_info=True)
            await storage.update_job_status(job_id, "failed", None, str(e))
    
    background_tasks.add_task(generate_task)
    await storage.create_job(job_id, "manual_ui", data.dict())
    
    logger.info(f"–¢–µ—Å—Ç–æ–≤—ã –ª–æ–≥ {job_id}")
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–∞—á–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤",
        "estimated_time": 30,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.post("/api/testcases/manual/api")
async def generate_manual_api_testcases(data: APIGenerationRequest, background_tasks: BackgroundTasks):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—É—á–Ω—ã—Ö API —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤"""
    job_id = str(uuid.uuid4())
    
    async def generate_task():
        try:
            logger.info(f"–ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ API —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤ –¥–ª—è job_id: {job_id}")
            logger.debug(f"–î–∞–Ω–Ω—ã–µ: {data.dict()}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            await storage.update_job_status(job_id, "processing", None, None, 10)
            
            # –ü–∞—Ä—Å–∏–Ω–≥ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
            parser = OpenAPIParser()
            spec = {}
            
            if data.openapi_url:
                logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ OpenAPI –∏–∑ URL: {data.openapi_url}")
                spec = await parser.parse_from_url(data.openapi_url)
            elif data.openapi_content:
                logger.info("–ü–∞—Ä—Å–∏–Ω–≥ OpenAPI –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
                spec = parser.parse_from_content(data.openapi_content)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –∏–∑ cloud.ru
                logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ OpenAPI URL –∏–∑ cloud.ru")
                try:
                    # –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ URL
                    spec = await parser.parse_from_url("https://cloud.ru/docs/api/cdn/virtual-machines/ug/_specs/openapi-v3.yaml")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é: {e}")
                    # Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –µ—Å—Ç—å
                    try:
                        with open("cloud_docs.yaml", "r", encoding="utf-8") as f:
                            spec = parser.parse_from_content(f.read())
                    except Exception as e2:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é: {e2}")
                        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if not spec or not parser.validate_spec(spec):
                raise ValueError("–ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞—è OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è")
            
            await storage.update_job_status(job_id, "processing", None, None, 30)
            
            logger.info(f"–î–∞–Ω–Ω—ã–µ: {data}")
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤
            logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è {data.target_count} API —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤ –¥–ª—è —Å–µ–∫—Ü–∏–π: {data.sections}")
            testcases = await testcase_generator.generate_api_testcases(
                openapi_spec=spec,
                sections=data.sections,
                count=data.target_count,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º target_count
                priority=data.priority,
                auth_type=data.auth_type
            )
            
            logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(testcases) if testcases else 0} API —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤")
            
            await storage.update_job_status(job_id, "processing", None, None, 80)
            
            await storage.save_testcases(job_id, testcases, "manual_api")
            await storage.update_job_status(job_id, "completed", testcases, None, 100)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ API —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤: {e}")
            import traceback
            logger.error(traceback.format_exc())
            await storage.update_job_status(job_id, "failed", None, str(e))
    
    background_tasks.add_task(generate_task)
    await storage.create_job(job_id, "manual_api", data.dict())
    
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–∞—á–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è API —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤",
        "estimated_time": 60,
        "progress": 10,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/testcases/{job_id}")
async def get_testcase_job(job_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤"""
    job = await storage.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return job

@app.get("/api/testcases/{job_id}/download")
async def download_testcases(job_id: str):
    """–°–∫–∞—á–∞—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç-–∫–µ–π—Å—ã"""
    zip_path = await storage.get_testcases_zip(job_id)
    if not zip_path or not os.path.exists(zip_path):
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return FileResponse(
        zip_path,
        media_type="application/zip",
        filename=f"testcases_{job_id}.zip"
    )

@app.post("/api/autotests/ui")
async def generate_ui_autotests(data: UIAutotestsRequest, background_tasks: BackgroundTasks):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è UI –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤ (Playwright)"""
    job_id = str(uuid.uuid4())
    
    async def generate_task():
        try:
            logger.info(f"[AUTOTEST-UI] –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è job_id: {job_id}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            await storage.update_job_status(job_id, "processing", None, None, 20)

            autotests = await autotest_generator.generate_ui_tests(
                manual_testcases_ids=data.manual_testcases_ids,
                framework=data.framework,
                browsers=data.browsers,
                base_url=data.base_url,
                headless=data.headless,
                priority_filter=data.priority_filter
            )
            
            logger.info(f"[AUTOTEST-UI] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(autotests) if autotests else 0} –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            await storage.update_job_status(job_id, "processing", None, None, 80)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≤—Ç–æ—Ç–µ—Å—Ç—ã
            zip_path = await storage.save_autotests(job_id, autotests, "ui")
            logger.info(f"[AUTOTEST-UI] –ê–≤—Ç–æ—Ç–µ—Å—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {zip_path}")
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            await storage.update_job_status(job_id, "completed", autotests, None, 100)
            logger.info(f"[AUTOTEST-UI] –ó–∞–¥–∞—á–∞ {job_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"[AUTOTEST-UI] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ UI –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤: {e}", exc_info=True)
            await storage.update_job_status(job_id, "failed", None, str(e))
    
    background_tasks.add_task(generate_task)
    await storage.create_job(job_id, "autotest_ui", data.dict())
    
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–∞—á–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è UI –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤",
        "estimated_time": 60,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.post("/api/autotests/api")
async def generate_api_autotests(data: APIAutotestsRequest, background_tasks: BackgroundTasks):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è API –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤ (pytest)"""
    job_id = str(uuid.uuid4())
    
    async def generate_task():
        try:
            logger.info(f"[AUTOTEST-API] –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è job_id: {job_id}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            await storage.update_job_status(job_id, "processing", None, None, 20)

            autotests = await autotest_generator.generate_api_tests(
                manual_testcases_ids=data.manual_testcases_ids,
                openapi_url=data.openapi_url,
                sections=data.sections,
                base_url=data.base_url,
                auth_token=data.auth_token,
                test_framework=data.test_framework,
                http_client=data.http_client
            )

            logger.info(f"[AUTOTEST-API] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(autotests) if autotests else 0} –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            await storage.update_job_status(job_id, "processing", None, None, 80)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≤—Ç–æ—Ç–µ—Å—Ç—ã
            zip_path = await storage.save_autotests(job_id, autotests, "api")
            logger.info(f"[AUTOTEST-API] –ê–≤—Ç–æ—Ç–µ—Å—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {zip_path}")
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            await storage.update_job_status(job_id, "completed", autotests, None, 100)
            logger.info(f"[AUTOTEST-API] –ó–∞–¥–∞—á–∞ {job_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"[AUTOTEST-API] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ API –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤: {e}", exc_info=True)
            await storage.update_job_status(job_id, "failed", None, str(e))

    background_tasks.add_task(generate_task)
    await storage.create_job(job_id, "autotest_api", data.dict())
    
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–∞—á–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è API –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤",
        "estimated_time": 50,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/autotests/{job_id}")
async def get_autotest_job(job_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤"""
    job = await storage.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return job

@app.get("/api/autotests/{job_id}/download")
async def download_autotests(job_id: str):
    """–°–∫–∞—á–∞—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ—Ç–µ—Å—Ç—ã"""
    zip_path = await storage.get_autotests_zip(job_id)
    if not zip_path or not os.path.exists(zip_path):
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return FileResponse(
        zip_path,
        media_type="application/zip",
        filename=f"autotests_{job_id}.zip"
    )

@app.post("/api/optimization/analyze")
async def analyze_optimization(data: OptimizationRequest, background_tasks: BackgroundTasks):
    """–ê–Ω–∞–ª–∏–∑ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤"""
    job_id = str(uuid.uuid4())
    
    async def analyze_task():
        try:
            result = await optimizer.analyze_and_optimize(
                repository_url=data.repository_url,
                requirements=data.requirements,
                checks=data.checks,
                optimization_level=data.optimization_level
            )
            
            await storage.save_optimization_result(job_id, result)
            await storage.update_job_status(job_id, "completed", result)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}", exc_info=True)
            await storage.update_job_status(job_id, "failed", None, str(e))
    
    background_tasks.add_task(analyze_task)
    await storage.create_job(job_id, "optimization", data.dict())
    
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–∞—á–∞—Ç –∞–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏",
        "estimated_time": 90,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/optimization/{job_id}")
async def get_optimization_job(job_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    job = await storage.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return job

@app.get("/api/optimization/{job_id}/download")
async def download_optimized(job_id: str):
    """–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    zip_path = await storage.get_optimization_zip(job_id)
    if not zip_path or not os.path.exists(zip_path):
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return FileResponse(
        zip_path,
        media_type="application/zip",
        filename=f"optimized_{job_id}.zip"
    )

@app.post("/api/standards/check")
async def check_standards(
    files: List[UploadFile] = File(...),
    checks: List[str] = Form(...)
):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º"""
    job_id = str(uuid.uuid4())
    
    # –í–ê–ñ–ù–û: —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –î–û –∑–∞–ø—É—Å–∫–∞ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏
    file_contents = []
    for file in files:
        content = await file.read()
        file_contents.append({
            "filename": file.filename,
            "content": content.decode("utf-8")
        })

    async def check_task():
        try:
            logger.info(f"[STANDARDS] –ù–∞—á–∞–ª–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è job_id: {job_id}")
            await storage.update_job_status(job_id, "processing", None, None, 30)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
            all_issues = []
            for file_data in file_contents:
                result = await standards_checker.check_testcase(file_data["content"])
                for issue in result.get("issues", []):
                    all_issues.append({
                        "file": file_data["filename"],
                        "line": 0,
                        "severity": issue.get("severity", "medium"),
                        "rule": issue.get("type", "unknown"),
                        "message": issue.get("message", ""),
                        "suggested_fix": ""
                    })
            
            logger.info(f"[STANDARDS] –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(all_issues)}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            if file_contents:
                report = await standards_checker.generate_standards_report(
                    testcase_code=file_contents[0]["content"],
                    include_suggestions=True
                )
            else:
                report = {}
            
            report_path = await storage.save_standards_report(job_id, report, all_issues)
            logger.info(f"[STANDARDS] HTML –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis
            await storage.update_job_status(job_id, "completed", {
                "report": report,
                "issues": all_issues,
                "issues_count": len(all_issues)
            }, None, 100)
            
        except Exception as e:  # üëà –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π except –ø–æ—Å–ª–µ try
            logger.error(f"[STANDARDS] –û—à–∏–±–∫–∞: {e}", exc_info=True)
            await storage.update_job_status(job_id, "failed", None, str(e))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–µ
    asyncio.create_task(check_task())
    await storage.create_job(job_id, "standards_check", {"checks": checks})
    
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –Ω–∞—á–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤",
        "estimated_time": 30,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/standards/{job_id}")
async def get_standards_job(job_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤"""
    job = await storage.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return job

@app.get("/api/standards/{job_id}/report")
async def download_standards_report(job_id: str):
    """–°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤"""
    report_path = await storage.get_standards_report(job_id)
    if not report_path or not os.path.exists(report_path):
        raise HTTPException(status_code=404, detail="–û—Ç—á–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return FileResponse(
        report_path,
        media_type="text/html",
        filename=f"standards_report_{job_id}.html"
    )

app.post("/api/testplan/generate")
async def generate_testplan(data: TestPlanRequest, background_tasks: BackgroundTasks):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç-–ø–ª–∞–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤"""
    job_id = str(uuid.uuid4())
    
    async def generate_task():
        try:
            logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç-–ø–ª–∞–Ω–∞: {job_id}")
            await storage.update_job_status(job_id, "processing", None, None, 30)
            
            testplan = await create_testplan_from_testcases(
                llm_client=llm_client,
                testcases=data.testcases,
                requirements=data.requirements,
                sprint_duration=data.sprint_duration,
                team_size=data.team_size
            )
            
            await storage.update_job_status(job_id, "completed", testplan, None, 100)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç-–ø–ª–∞–Ω–∞: {e}", exc_info=True)
            await storage.update_job_status(job_id, "failed", None, str(e))
    
    background_tasks.add_task(generate_task)
    await storage.create_job(job_id, "testplan", data.dict())
    
    return {
        "job_id": job_id,
        "status": "pending",
        "message": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç-–ø–ª–∞–Ω–∞ –Ω–∞—á–∞—Ç–∞",
        "estimated_time": 45,
        "created_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/testplan/{job_id}")
async def get_testplan_job(job_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ—Å—Ç-–ø–ª–∞–Ω"""
    job = await storage.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return job

@app.get("/api/testcases/")
async def list_testcase_jobs(
    status: Optional[str] = None,
    limit: int = 20,
    offset: int = 0
):
    """–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤"""
    jobs = await storage.list_jobs(job_type="testcase", status=status, limit=limit, offset=offset)
    return jobs

@app.get("/api/jobs/")
async def list_all_jobs(
    job_type: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = 20,
    offset: int = 0
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
    jobs = await storage.list_all_jobs(
        job_type=job_type,
        status=status,
        limit=limit,
        offset=offset
    )
    return jobs

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)